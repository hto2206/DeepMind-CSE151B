{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "new_test = \"./new_val_in/new_val_in\"\n",
    "\n",
    "\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "val_testset  = ArgoverseDataset(data_path=new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "batch_sz_test = 1\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    inp = torch.FloatTensor(inp)\n",
    "    out = torch.FloatTensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate1(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    inp = torch.FloatTensor(inp)\n",
    "    return inp\n",
    "\n",
    "test_loader = DataLoader(val_testset, batch_size=batch_sz_test, shuffle=True, collate_fn=my_collate1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "agent_id = 0\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "\n",
    "        \n",
    "for i_batch, sample_batch in enumerate(val_loader):\n",
    "    inp, out = sample_batch\n",
    "    show_sample_batch(sample_batch, agent_id)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class FCModule(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FCModule, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = 8192\n",
    "        self.linear2 = nn.Sequential(nn.Linear(240*19, self.hidden_dim), nn.ReLU(), nn.Linear(self.hidden_dim, 240*30))\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward_test(self, x, num_steps = 30):\n",
    "        res=[]\n",
    "        h = torch.zeros((self.num_layers,len(x),self.hidden_dim)).cuda()\n",
    "        c = torch.zeros((self.num_layers,len(x),self.hidden_dim)).cuda()\n",
    "        for step in range(num_steps):\n",
    "            x, (h,c) = self.lstm(x, (h,c))\n",
    "            x = x[:,-1:]\n",
    "            x = x.transpose(1,2)\n",
    "            x = self.linear(x)\n",
    "            x = x.transpose(1,2)\n",
    "            res.append(x)\n",
    "        res = torch.cat(res,1)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss full 0 0 744.3157348632812 744.3157348632812\n",
      "loss full 0 10 724.7899780273438 592.5497436523438\n",
      "loss full 0 20 681.576171875 270.40728759765625\n",
      "loss full 0 30 642.2749633789062 149.43995666503906\n",
      "loss full 0 40 605.6919555664062 327.7553405761719\n",
      "loss full 0 50 570.0564575195312 160.70249938964844\n",
      "loss full 0 60 532.7153930664062 157.03065490722656\n",
      "loss full 0 70 499.8044128417969 194.8953094482422\n",
      "loss full 0 80 468.3074951171875 169.29197692871094\n",
      "loss full 0 90 439.1110534667969 146.79364013671875\n",
      "loss full 0 100 413.6964416503906 210.22389221191406\n",
      "loss full 0 110 387.03070068359375 117.97724914550781\n",
      "loss full 0 120 363.0111999511719 126.11384582519531\n",
      "loss full 0 130 343.6921081542969 105.73490905761719\n",
      "loss full 0 140 329.0838623046875 157.39584350585938\n",
      "loss full 0 150 313.7799072265625 84.70704650878906\n",
      "loss full 0 160 299.2543640136719 160.8965301513672\n",
      "loss full 0 170 285.0349426269531 160.56690979003906\n",
      "loss full 0 180 272.7681884765625 191.34771728515625\n",
      "loss full 0 190 260.551513671875 101.42271423339844\n",
      "loss full 0 200 249.18515014648438 132.16534423828125\n",
      "loss full 0 210 238.8576202392578 102.21419525146484\n",
      "loss full 0 220 228.77590942382812 97.42308807373047\n",
      "loss full 0 230 219.31507873535156 174.14695739746094\n",
      "loss full 0 240 210.7699432373047 113.91108703613281\n",
      "loss full 0 250 202.1953125 134.6760711669922\n",
      "loss full 0 260 194.35214233398438 100.53484344482422\n",
      "loss full 0 270 187.81983947753906 116.35684204101562\n",
      "loss full 0 280 181.78897094726562 113.78023529052734\n",
      "loss full 0 290 175.80764770507812 79.90138244628906\n",
      "loss full 0 300 170.21469116210938 73.74331665039062\n",
      "loss full 0 310 166.0972442626953 223.03939819335938\n",
      "loss full 0 320 161.0684051513672 100.49430847167969\n",
      "loss full 0 330 155.75341796875 175.02296447753906\n",
      "loss full 0 340 153.3330078125 115.50102996826172\n",
      "loss full 0 350 150.945068359375 134.40538024902344\n",
      "loss full 0 360 148.93893432617188 80.0409164428711\n",
      "loss full 0 370 146.85313415527344 169.38638305664062\n",
      "loss full 0 380 142.88900756835938 152.53082275390625\n",
      "loss full 0 390 138.9166259765625 81.7490005493164\n",
      "loss full 0 400 133.35476684570312 130.06283569335938\n",
      "loss full 0 410 129.0471649169922 117.36174011230469\n",
      "loss full 0 420 126.99742126464844 116.51808166503906\n",
      "loss full 0 430 127.72447204589844 329.3238220214844\n",
      "loss full 0 440 124.61702728271484 66.40032196044922\n",
      "loss full 0 450 121.24128723144531 92.23497772216797\n",
      "loss full 0 460 120.46259307861328 157.49221801757812\n",
      "loss full 0 470 119.53736114501953 313.2986755371094\n",
      "loss full 0 480 117.3783950805664 50.293373107910156\n",
      "loss full 0 490 116.60536193847656 117.68661499023438\n",
      "loss full 0 500 118.7894058227539 131.5055389404297\n",
      "loss full 0 510 120.06739807128906 110.8979263305664\n",
      "loss full 0 520 117.72795104980469 86.38298797607422\n",
      "loss full 0 530 115.61185455322266 109.01202392578125\n",
      "loss full 0 540 112.86515045166016 83.01408386230469\n",
      "loss full 0 550 110.94377899169922 81.26280975341797\n",
      "loss full 0 560 108.43453979492188 74.90476989746094\n",
      "loss full 0 570 106.68907165527344 56.65679168701172\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = \"cuda:0\"\n",
    "model = FCModule().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "loss_ema = -1\n",
    "loss_ema2 = -1\n",
    "\n",
    "for epoch in range(5):\n",
    "    for i_batch, sample_batch in enumerate (val_loader):\n",
    "        inp,out = sample_batch\n",
    "        inp = inp.cuda()\n",
    "        out = out.cuda()\n",
    "        mixed = torch.cat([inp,out],2).transpose(1,2).reshape(-1,49,240)\n",
    "        y_pred = model(inp.reshape(len(inp),-1)).reshape(-1,60,30,4)\n",
    "        loss = (torch.mean((y_pred-out)**2))**0.5\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if loss_ema < 0:\n",
    "            loss_ema = loss\n",
    "        loss_ema = loss_ema*0.99 + loss*0.01\n",
    "        \n",
    "        if i_batch%10 == 0:\n",
    "            print('loss full', epoch, i_batch, loss_ema.item(), loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
