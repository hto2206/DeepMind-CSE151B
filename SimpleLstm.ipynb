{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "new_test = \"./new_val_in/new_val_in\"\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "val_testset  = ArgoverseDataset(data_path=new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "batch_sz_test = 1\n",
    "\n",
    "# For Miami Dataset\n",
    "def my_collate_val_MIA(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inpMIA = []\n",
    "    outMIA = []\n",
    "    \n",
    "    for scene in batch:\n",
    "        if scene['city'] == 'MIA':\n",
    "            inpMIA = [numpy.dstack([scene['p_in'], scene['v_in']])]\n",
    "            outMIA = [numpy.dstack([scene['p_out'], scene['v_out']])]\n",
    "    \n",
    "    inpMIA = torch.FloatTensor(inpMIA)\n",
    "    outMIA = torch.FloatTensor(outMIA)\n",
    "    return [inpMIA, outMIA]\n",
    "\n",
    "def my_collate_val_PIT(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inpPIT = []\n",
    "    outPIT = []\n",
    "    \n",
    "    for scene in batch:\n",
    "        if scene['city'] == 'PIT':\n",
    "            inpPIT = [numpy.dstack([scene['p_in'], scene['v_in']])]\n",
    "            outPIT = [numpy.dstack([scene['p_out'], scene['v_out']])]\n",
    "                \n",
    "    \n",
    "    inpPIT = torch.FloatTensor(inpPIT)\n",
    "    outMIA = torch.FloatTensor(outPIT)\n",
    "    return [inpPIT, outPIT]\n",
    "\n",
    "val_loader_MIA = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, \n",
    "                            collate_fn=my_collate_val_MIA, num_workers=0)\n",
    "val_loader_PIT = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, \n",
    "                            collate_fn=my_collate_val_PIT, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Miami Dataset\n",
    "def my_collate_train_MIA(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inpMIA = []\n",
    "    outMIA = []\n",
    "    \n",
    "    for scene in batch:\n",
    "        if scene['city'] == 'MIA':\n",
    "            inpMIA = [numpy.dstack([scene['p_in'], scene['v_in']])]\n",
    "            outMIA = [numpy.dstack([scene['p_out'], scene['v_out']])]\n",
    "    \n",
    "    inpMIA = torch.FloatTensor(inpMIA)\n",
    "    outMIA = torch.FloatTensor(outMIA)\n",
    "    return [inpMIA, outMIA]\n",
    "\n",
    "def my_collate_train_PIT(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inpPIT = []\n",
    "    outPIT = []\n",
    "    \n",
    "    for scene in batch:\n",
    "        if scene['city'] == 'PIT':\n",
    "            inpPIT = [numpy.dstack([scene['p_in'], scene['v_in']])]\n",
    "            outPIT = [numpy.dstack([scene['p_out'], scene['v_out']])]\n",
    "                \n",
    "    \n",
    "    inpPIT = torch.FloatTensor(inpPIT)\n",
    "    outMIA = torch.FloatTensor(outPIT)\n",
    "    return [inpPIT, outPIT]\n",
    "\n",
    "test_loader_MIA = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, \n",
    "                            collate_fn=my_collate_train_MIA, num_workers=0)\n",
    "test_loader_PIT = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, \n",
    "                            collate_fn=my_collate_train_PIT, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = 2000\n",
    "        self.num_layers=3\n",
    "        self.lstm = nn.LSTM(240, self.hidden_dim, num_layers=self.num_layers, batch_first = True)\n",
    "        self.linear1 = nn.Conv1d(self.hidden_dim, 240, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x,_ = self.lstm(x)\n",
    "        x = torch.transpose(x,1,2)\n",
    "        x = self.linear1(x)\n",
    "        x = torch.transpose(x,1,2)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward_test(self, x, num_steps = 30):\n",
    "        res=[]\n",
    "        h = torch.zeros((self.num_layers,len(x),self.hidden_dim)).cuda()\n",
    "        c = torch.zeros((self.num_layers,len(x),self.hidden_dim)).cuda()\n",
    "        for step in range(num_steps):\n",
    "            x, (h,c) = self.lstm(x, (h,c))\n",
    "            x = x[:,-1:]\n",
    "            x = torch.transpose(x,1,2)\n",
    "            x = self.linear1(x)\n",
    "            x = torch.transpose(x,1,2)\n",
    "            res.append(x)\n",
    "        res = torch.cat(res,1)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "loss full 0 0 902.48291015625 902.48291015625\n",
      "loss test 0 0 902.315673828125 902.31396484375\n",
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "loss full 0 10 869.6507568359375 388.4565124511719\n",
      "loss test 0 10 869.4994506835938 388.16656494140625\n",
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "torch.Size([1, 60, 19, 4])\n",
      "torch.Size([1, 60, 30, 4])\n",
      "torch.Size([0])\n",
      "torch.Size([0])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6ede0b39a993>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mmixed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mmixed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m49\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = \"cuda:0\"\n",
    "model = LSTM().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "loss_ema = -1\n",
    "loss_ema2 = -1\n",
    "\n",
    "# For MIA\n",
    "for epoch in range(1):\n",
    "    for i_batch, sample_batch in enumerate (val_loader_MIA):\n",
    "        inp,out = sample_batch\n",
    "        inp = inp.cuda()\n",
    "        out = out.cuda()\n",
    "        # mixed = torch.cat([inp,out],2).transpose(1,2).reshape(-1,49,240)\n",
    "        mixed = torch.cat([inp,out],2)\n",
    "        print(inp.shape)\n",
    "        print(out.shape)\n",
    "        mixed = mixed.transpose(1, 2)\n",
    "        mixed = mixed.reshape(-1, 49, 240)\n",
    "        y_pred = model(mixed[:,:-1])[:,-30:]\n",
    "        y_pred = y_pred.reshape(-1,30,60,4).transpose(1,2)\n",
    "        loss = (torch.mean((y_pred-out)**2))**0.5\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if loss_ema < 0:\n",
    "            loss_ema = loss\n",
    "        loss_ema = loss_ema*0.99 + loss*0.01\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred2 = model.forward_test(inp.transpose(1,2).reshape(-1,19,240))\n",
    "            y_pred2 = y_pred2.reshape(-1, 30, 60, 4).transpose(1,2)\n",
    "            loss2 = torch.mean((y_pred2-out)**2)**0.5\n",
    "            if loss_ema2 < 0:\n",
    "                loss_ema2 = loss2\n",
    "            loss_ema2 = loss_ema2*0.99 + loss*0.01\n",
    "        \n",
    "        if i_batch%10 == 0:\n",
    "            print('loss full', epoch, i_batch, loss_ema.item(), loss.item())\n",
    "            print('loss test', epoch, i_batch, loss_ema2.item(), loss2.item())\n",
    "            \n",
    "torch.save(model.state_dict(),\"Simple_LSTM_MIA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For PIT\n",
    "for epoch in range(1):\n",
    "    for i_batch, sample_batch in enumerate (val_loader_PIT):\n",
    "        inp,out = sample_batch\n",
    "        inp = inp.cuda()\n",
    "        out = out.cuda()\n",
    "        mixed = torch.cat([inp,out],2).transpose(1,2).reshape(-1,49,240)\n",
    "        y_pred = model(mixed[:,:-1])[:,-30:]\n",
    "        y_pred = y_pred.reshape(-1,30,60,4).transpose(1,2)\n",
    "        loss = (torch.mean((y_pred-out)**2))**0.5\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if loss_ema < 0:\n",
    "            loss_ema = loss\n",
    "        loss_ema = loss_ema*0.99 + loss*0.01\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred2 = model.forward_test(inp.transpose(1,2).reshape(-1,19,240))\n",
    "            y_pred2 = y_pred2.reshape(-1, 30, 60, 4).transpose(1,2)\n",
    "            loss2 = torch.mean((y_pred2-out)**2)**0.5\n",
    "            if loss_ema2 < 0:\n",
    "                loss_ema2 = loss2\n",
    "            loss_ema2 = loss_ema2*0.99 + loss*0.01\n",
    "        \n",
    "        if i_batch%10 == 0:\n",
    "            print('loss full', epoch, i_batch, loss_ema.item(), loss.item())\n",
    "            print('loss test', epoch, i_batch, loss_ema2.item(), loss2.item())\n",
    "torch.save(model.state_dict(),\"Simple_LSTM_PIT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
